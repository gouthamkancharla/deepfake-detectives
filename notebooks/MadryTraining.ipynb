{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oP1aYkvFof61"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --quiet\n",
    "!pip install tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ich8mxy6oX0s"
   },
   "outputs": [],
   "source": [
    "!pip3 install face_recognition\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "\n",
    "# --- Set device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Change directory and load splits ---\n",
    "os.chdir(\"/content/drive/MyDrive/csc490/code_and_datasets/video_splits_output\")\n",
    "train_files = read_list(\"train.txt\")\n",
    "val_files   = read_list(\"val.txt\")\n",
    "test_files  = read_list(\"test.txt\")\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\"Train:\", len(train_files))\n",
    "print(\"Val:\", len(val_files))\n",
    "print(\"Test:\", len(test_files))\n",
    "\n",
    "train_labels = pd.DataFrame({\n",
    "    \"file\": [os.path.basename(p) for p in train_files],\n",
    "    \"label\": [assign_label(p) for p in train_files]\n",
    "})\n",
    "val_labels = pd.DataFrame({\n",
    "    \"file\": [os.path.basename(p) for p in val_files],\n",
    "    \"label\": [assign_label(p) for p in val_files]\n",
    "})\n",
    "test_labels = pd.DataFrame({\n",
    "    \"file\": [os.path.basename(p) for p in test_files],\n",
    "    \"label\": [assign_label(p) for p in test_files]\n",
    "})\n",
    "\n",
    "print(\"Train Real:\", sum(train_labels.label == 0), \"Fake:\", sum(train_labels.label == 1))\n",
    "print(\"Val   Real:\", sum(val_labels.label == 0),   \"Fake:\", sum(val_labels.label == 1))\n",
    "print(\"Test  Real:\", sum(test_labels.label == 0),  \"Fake:\", sum(test_labels.label == 1))\n",
    "\n",
    "# --- Define transforms ---\n",
    "im_size = 112\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# --- Create Dataset objects ---\n",
    "train_data = video_dataset(\n",
    "    video_names=train_files,\n",
    "    labels=train_labels,\n",
    "    sequence_length=10,\n",
    "    transform=train_transforms\n",
    ")\n",
    "val_data = video_dataset(\n",
    "    video_names=val_files,\n",
    "    labels=val_labels,\n",
    "    sequence_length=10,\n",
    "    transform=test_transforms\n",
    ")\n",
    "test_data = video_dataset(\n",
    "    video_names=test_files,\n",
    "    labels=test_labels,\n",
    "    sequence_length=10,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(val_data, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_data,  batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- PGD attack function ---\n",
    "def pgd_attack(model, x, target_label, epsilon=0.05, alpha=0.01, steps=5):\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    for _ in range(steps):\n",
    "        _, logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, target_label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            # Targeted attack: move toward target_label\n",
    "            x_adv = x_adv - alpha * x_adv.grad.sign()\n",
    "            x_adv = torch.min(torch.max(x_adv, x - epsilon), x + epsilon)\n",
    "            x_adv = x_adv.clamp(0, 1)\n",
    "            x_adv.requires_grad_(True)\n",
    "    model.train()\n",
    "    return x_adv.detach()\n",
    "\n",
    "# --- Learning rate and optimizer ---\n",
    "lr = 1e-5\n",
    "num_epochs = 20\n",
    "model = Model(2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_loss_avg = []\n",
    "train_accuracy = []\n",
    "test_loss_avg = []\n",
    "test_accuracy = []\n",
    "start_epoch, best_acc = 1, 0.0\n",
    "\n",
    "# --- TRAINING LOOP WITH MADRY STYLE ---\n",
    "for epoch in range(start_epoch, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clone inputs for adversarial attack\n",
    "        inputs_adv = inputs.clone().detach()\n",
    "\n",
    "        # Only attack fake videos (label==1)\n",
    "        fake_mask = (labels == 1)\n",
    "        target_real = torch.zeros_like(labels)  # targeted to REAL class\n",
    "\n",
    "        if fake_mask.any():\n",
    "            inputs_fake = inputs_adv[fake_mask]\n",
    "            targets_fake = target_real[fake_mask]\n",
    "            adv_fake = pgd_attack(model, inputs_fake, targets_fake, epsilon=0.05, alpha=0.01, steps=5)\n",
    "            inputs_adv[fake_mask] = adv_fake\n",
    "\n",
    "        # Forward pass\n",
    "        _, logits = model(inputs_adv)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss_avg.append(running_loss / total)\n",
    "    train_accuracy.append(correct / total)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    true, pred, probs, val_loss, val_acc = test(epoch, model, valid_loader, criterion)\n",
    "    test_loss_avg.append(val_loss)\n",
    "    test_accuracy.append(val_acc)\n",
    "\n",
    "    # --- SAVE BEST MODEL ---\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        save_checkpoint({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"best_acc\": best_acc\n",
    "        })\n",
    "        print(f\"New best model saved with accuracy {best_acc:.2f}%\")\n",
    "\n",
    "# --- Load best model ---\n",
    "load_checkpoint(model, optimizer, \"/content/drive/MyDrive/csc490/code_and_datasets/checkpoints/no_pretraining_madry_style.pth\")\n",
    "\n",
    "# --- Plot results ---\n",
    "plot_loss(train_loss_avg, test_loss_avg, len(train_loss_avg))\n",
    "plot_accuracy(train_accuracy, test_accuracy, len(train_accuracy))\n",
    "\n",
    "# --- Confusion matrix, F1, ROC ---\n",
    "if true and pred and probs:\n",
    "    print_confusion_matrix(true, pred)\n",
    "    f1 = f1_score(true, pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    fpr, tpr, thresholds = roc_curve(true, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.4f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping confusion matrix, F1 score, and ROC plot due to incomplete validation data. Please run the training loop to completion.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Lr_jWqKNlEn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
