{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"GNq7lqK7Vgqy"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m98.9/100.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]},{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2277403752.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 18\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mTXT_FOLDER_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--\u003e 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["\n","!pip install torch torchvision torchaudio tqdm face_recognition pandas timm opencv-python --quiet\n","\n","import os\n","import cv2\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import timm\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive', force_remount=True)\n","\n","TXT_FOLDER_PATH = \"/content\"\n","\n","print(f\"checking text file: {TXT_FOLDER_PATH}\")\n","\n","if not os.path.exists(os.path.join(TXT_FOLDER_PATH, \"train.txt\")):\n","    raise FileNotFoundError(\"Files not uploaded\")\n","else:\n","    print(\"found file\")\n","\n","CONFIG = {\n","    \"gpu_id\": 0, \"batch_size\": 8,\n","    \"epochs\": 1,\n","    \"lr\": 1e-4,\n","    \"epsilon\": 0.05, \"alpha\": 0.01, \"pgd_steps\": 1,\n","    \"adv_ratio\": 0.5,\n","    \"sequence_length\": 5, \"im_size\": 299, \"w_clean\": 0.6, \"w_adv\": 0.4,\n","    \"base_path\": TXT_FOLDER_PATH,\n","    \"checkpoint_dir\": \"/content/drive/MyDrive/csc490/code_and_datasets/checkpoints\"\n","}\n","os.makedirs(CONFIG[\"checkpoint_dir\"], exist_ok=True)\n","device = torch.device(f\"cuda:{CONFIG['gpu_id']}\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_transforms = transforms.Compose([\n","    transforms.ToPILImage(), transforms.Resize((299, 299)), transforms.ToTensor(),\n","])\n","\n","class DeepfakeVideoDataset(Dataset):\n","    def __init__(self, txt_filename, sequence_length, transform=None, limit=None):\n","        file_path = os.path.join(CONFIG['base_path'], txt_filename)\n","        if not os.path.exists(file_path):\n","            self.video_paths = []\n","        else:\n","            with open(file_path, 'r') as f:\n","                lines = [line.strip() for line in f.readlines() if line.strip()]\n","\n","            if limit and len(lines) \u003e limit: self.video_paths = lines[:limit]\n","            else: self.video_paths = lines\n","        self.sequence_length = sequence_length\n","        self.transform = transform\n","\n","    def __len__(self): return len(self.video_paths)\n","    def get_label(self, path): return 0 if \"original\" in path.lower() else 1\n","    def __getitem__(self, idx):\n","        video_path = self.video_paths[idx]\n","        label = self.get_label(video_path)\n","        try:\n","            cap = cv2.VideoCapture(video_path)\n","            cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","            indices = sorted(random.sample(range(cnt), self.sequence_length)) if cnt \u003e self.sequence_length else list(range(cnt))\n","            frames = []\n","            for i in range(cnt):\n","                ret, frame = cap.read()\n","                if not ret: break\n","                if i in indices:\n","                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","                    if self.transform: frame = self.transform(frame)\n","                    frames.append(frame)\n","            cap.release()\n","        except: frames = []\n","        if len(frames) == 0: return torch.zeros((self.sequence_length, 3, 299, 299)), label\n","        while len(frames) \u003c self.sequence_length: frames.append(frames[-1])\n","        return torch.stack(frames), label\n","\n","class VideoXception(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = timm.create_model('xception', pretrained=True, num_classes=2)\n","    def forward(self, x):\n","        b, s, c, h, w = x.shape\n","        x = x.view(b*s, c, h, w)\n","        x = (x - torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1,3,1,1)) / \\\n","            torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1,3,1,1)\n","        logits = self.backbone(x)\n","        return torch.mean(logits.view(b, s, -1), dim=1)\n","\n","def pgd_attack(model, x, y, eps, alpha, steps):\n","    model.eval()\n","    x_adv = x.clone().detach().requires_grad_(True)\n","    for _ in range(steps):\n","        out = model(x_adv)\n","        loss = F.cross_entropy(out, y)\n","        model.zero_grad()\n","        loss.backward()\n","        with torch.no_grad():\n","            x_adv += alpha * x_adv.grad.sign()\n","            delta = torch.clamp(x_adv - x, -eps, eps)\n","            x_adv = torch.clamp(x + delta, 0, 1)\n","            x_adv.requires_grad_(True)\n","    model.train()\n","    return x_adv.detach()\n","\n","def main():\n","\n","    train_ds = DeepfakeVideoDataset(\"train.txt\", CONFIG['sequence_length'], train_transforms, limit=32)\n","    val_clean_ds = DeepfakeVideoDataset(\"val_clean.txt\", CONFIG['sequence_length'], train_transforms, limit=16)\n","    val_adv_ds = DeepfakeVideoDataset(\"val_adv.txt\", CONFIG['sequence_length'], train_transforms, limit=16)\n","\n","    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n","    val_clean_loader = DataLoader(val_clean_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n","    val_adv_loader = DataLoader(val_adv_ds, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n","\n","    model = VideoXception().to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])\n","    criterion = nn.CrossEntropyLoss()\n","\n","    print(f\"\\nSTARTING EPOCH 1/1 (Fast Run)...\")\n","    model.train()\n","    t_corr, t_total = 0, 0\n","\n","    for x, y in tqdm(train_loader):\n","        x, y = x.to(device), y.to(device)\n","        if random.random() \u003c CONFIG['adv_ratio']:\n","            x = pgd_attack(model, x, y, CONFIG['epsilon'], CONFIG['alpha'], CONFIG['pgd_steps'])\n","        out = model(x)\n","        loss = criterion(out, y)\n","        optimizer.zero_grad(); loss.backward(); optimizer.step()\n","        t_corr += out.argmax(1).eq(y).sum().item(); t_total += x.size(0)\n","\n","    print(f\"\\n Train Done Acc: {100.*t_corr/t_total:.2f}%\")\n","\n","    # Validation\n","    model.eval()\n","    def validate(loader):\n","        c, t = 0, 0\n","        if len(loader)==0: return 0.0\n","        with torch.no_grad():\n","            for x, y in loader:\n","                x, y = x.to(device), y.to(device)\n","                c += model(x).argmax(1).eq(y).sum().item(); t += x.size(0)\n","        return 100.*c/t\n","\n","    acc_clean = validate(val_clean_loader)\n","    acc_adv = validate(val_adv_loader)\n","\n","    print(f\"------------- FINAL RESULT -------------\")\n","    print(f\"Val Clean Acc : {acc_clean:.2f}%\")\n","    print(f\"Val Robust Acc: {acc_adv:.2f}%\")\n","    print(f\"----------------------------------------\")\n","\n","    torch.save(model.state_dict(), \"final_result_model.pth\")\n","    print(\"saved\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPEREaocVkP3G91zLvsNZ3v","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}